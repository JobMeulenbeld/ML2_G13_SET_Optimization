{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28961c5-9b68-46f1-bf46-1e423938ec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Author: Decebal Constantin Mocanu et al. (legacy SET-MLP CIFAR-10)\n",
    "# TensorFlow 2 / Keras 3 + Neuron-level EMA growth bias\n",
    "#\n",
    "# Method change:\n",
    "# - Pruning: same as legacy SET (weight-based thresholds near 0)\n",
    "# - Growth: biased toward neurons that are persistently active\n",
    "#          using EMA of mean absolute activations (neuron-level importance)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a583cdea-1df4-4668-8d28-5ec6d0af229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# SReLU\n",
    "# ----------------------------\n",
    "class SReLU(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.tl = self.add_weight(\n",
    "            name=\"tl\", shape=(), initializer=tf.keras.initializers.Constant(-1.0)\n",
    "        )\n",
    "        self.tr = self.add_weight(\n",
    "            name=\"tr\", shape=(), initializer=tf.keras.initializers.Constant(1.0)\n",
    "        )\n",
    "        self.al = self.add_weight(\n",
    "            name=\"al\", shape=(), initializer=tf.keras.initializers.Constant(0.2)\n",
    "        )\n",
    "        self.ar = self.add_weight(\n",
    "            name=\"ar\", shape=(), initializer=tf.keras.initializers.Constant(0.2)\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "            x < self.tl,\n",
    "            self.tl + self.al * (x - self.tl),\n",
    "            tf.where(\n",
    "                x > self.tr,\n",
    "                self.tr + self.ar * (x - self.tr),\n",
    "                x\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c6ad04-8074-4ab9-9272-bba286de8511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Utility helpers (legacy logic)\n",
    "# ----------------------------\n",
    "def find_first_pos(array, value):\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def find_last_pos(array, value):\n",
    "    idx = (np.abs(array - value))[::-1].argmin()\n",
    "    return array.shape[0] - idx\n",
    "\n",
    "\n",
    "def createWeightsMask(epsilon, noRows, noCols):\n",
    "    \"\"\"\n",
    "    Generate an Erdos-Renyi sparse mask.\n",
    "    \"\"\"\n",
    "    mask_weights = np.random.rand(noRows, noCols).astype(np.float32)\n",
    "    prob = 1 - (epsilon * (noRows + noCols)) / (noRows * noCols)\n",
    "    mask_weights[mask_weights < prob] = 0.0\n",
    "    mask_weights[mask_weights >= prob] = 1.0\n",
    "    noParameters = int(np.sum(mask_weights))\n",
    "    print(\"Create Sparse Matrix: No parameters, NoRows, NoCols \", noParameters, noRows, noCols)\n",
    "    return noParameters, mask_weights\n",
    "\n",
    "\n",
    "def safe_probs(scores: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert nonnegative scores to a probability distribution.\n",
    "    If all scores are ~0, return uniform.\n",
    "    \"\"\"\n",
    "    s = np.asarray(scores, dtype=np.float64)\n",
    "    s = np.maximum(s, 0.0)\n",
    "    total = float(s.sum())\n",
    "    if not np.isfinite(total) or total <= 1e-12:\n",
    "        return np.ones_like(s, dtype=np.float64) / float(s.size)\n",
    "    return s / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37442939-b80d-431e-a3ea-bdc0057d21aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Batch-tracking generator\n",
    "# ----------------------------\n",
    "class TrackingFlow:\n",
    "    \"\"\"\n",
    "    Wraps a Keras/Numpy iterator (e.g., datagen.flow) and stores last batch X\n",
    "    so the callback can compute activations.\n",
    "    \"\"\"\n",
    "    def __init__(self, iterator, parent):\n",
    "        self.it = iterator\n",
    "        self.p = parent\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            x, y = next(self.it)\n",
    "            self.p.last_batch_x = x\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd07666c-8831-4677-a34e-683bd7d02af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Callback implementing:\n",
    "# - mask enforcement per batch\n",
    "# - neuron activation EMA updates (every N batches)\n",
    "# - rewiring at epoch end (growth biased by EMA)\n",
    "# ----------------------------\n",
    "class SETCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, parent):\n",
    "        super().__init__()\n",
    "        self.p = parent\n",
    "\n",
    "    @staticmethod\n",
    "    def _apply_mask_to_layer(layer: tf.keras.layers.Dense, mask_np: np.ndarray):\n",
    "        mask_tf = tf.convert_to_tensor(mask_np, dtype=layer.kernel.dtype)\n",
    "        layer.kernel.assign(layer.kernel * mask_tf)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.p.current_epoch = int(epoch)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        # 1) Enforce full masks (keeps forbidden connections at exactly 0)\n",
    "        l1 = self.model.get_layer(\"sparse_1\")\n",
    "        l2 = self.model.get_layer(\"sparse_2\")\n",
    "        l3 = self.model.get_layer(\"sparse_3\")\n",
    "\n",
    "        self._apply_mask_to_layer(l1, self.p.wm1)\n",
    "        self._apply_mask_to_layer(l2, self.p.wm2)\n",
    "        self._apply_mask_to_layer(l3, self.p.wm3)\n",
    "\n",
    "        # 2) Update neuron-activity EMA every N batches (performance)\n",
    "        if (batch % self.p.act_update_every) != 0:\n",
    "            return\n",
    "\n",
    "        x = self.p.last_batch_x\n",
    "        if x is None:\n",
    "            return\n",
    "\n",
    "        # Input \"neurons\" (flattened pixels/features)\n",
    "        xf = x.reshape((x.shape[0], -1)).astype(np.float32)  # (B, 3072)\n",
    "        inp_batch = np.mean(np.abs(xf), axis=0)              # (3072,)\n",
    "\n",
    "        # Hidden neuron activations (after SReLU, before dropout)\n",
    "        a1, a2, a3 = self.p.act_model(x, training=False)\n",
    "        a1 = tf.reduce_mean(tf.abs(a1), axis=0).numpy()\n",
    "        a2 = tf.reduce_mean(tf.abs(a2), axis=0).numpy()\n",
    "        a3 = tf.reduce_mean(tf.abs(a3), axis=0).numpy()\n",
    "\n",
    "        b = self.p.beta_act\n",
    "        self.p.inp_ema = b * self.p.inp_ema + (1 - b) * inp_batch\n",
    "        self.p.act1_ema = b * self.p.act1_ema + (1 - b) * a1\n",
    "        self.p.act2_ema = b * self.p.act2_ema + (1 - b) * a2\n",
    "        self.p.act3_ema = b * self.p.act3_ema + (1 - b) * a3\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Store validation accuracy\n",
    "        if logs is not None:\n",
    "            va = logs.get(\"val_accuracy\", None)\n",
    "            if va is None:\n",
    "                va = logs.get(\"val_acc\", None)\n",
    "            if va is not None:\n",
    "                self.p.accuracies_per_epoch.append(float(va))\n",
    "\n",
    "        # Rewire masks at epoch end\n",
    "        self.p.weightsEvolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927b99b2-e2bf-486c-a879-04032067a5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Main model class\n",
    "# ----------------------------\n",
    "class SET_MLP_CIFAR10:\n",
    "    def __init__(self):\n",
    "        # SET parameters\n",
    "        self.epsilon = 20\n",
    "        self.zeta = 0.3\n",
    "        self.batch_size = 100\n",
    "        self.maxepoches = 1000\n",
    "        self.learning_rate = 0.01\n",
    "        self.num_classes = 10\n",
    "        self.momentum = 0.9\n",
    "\n",
    "        # Neuron-level EMA parameters\n",
    "        self.beta_act = 0.99\n",
    "        self.burn_in_epochs = 10       # uniform growth before this epoch\n",
    "        self.act_update_every = 10     # update activation EMA every N batches\n",
    "        self.current_epoch = 0\n",
    "        self.last_batch_x = None\n",
    "\n",
    "        # ER masks\n",
    "        self.noPar1, self.wm1 = createWeightsMask(self.epsilon, 32 * 32 * 3, 4000)\n",
    "        self.noPar2, self.wm2 = createWeightsMask(self.epsilon, 4000, 1000)\n",
    "        self.noPar3, self.wm3 = createWeightsMask(self.epsilon, 1000, 4000)\n",
    "\n",
    "        # Neuron activity EMA buffers\n",
    "        self.inp_ema = np.zeros(3072, dtype=np.float32)\n",
    "        self.act1_ema = np.zeros(4000, dtype=np.float32)\n",
    "        self.act2_ema = np.zeros(1000, dtype=np.float32)\n",
    "        self.act3_ema = np.zeros(4000, dtype=np.float32)\n",
    "\n",
    "        # Acc tracking\n",
    "        self.accuracies_per_epoch = []\n",
    "\n",
    "        # Build model + activation probe\n",
    "        self.create_model()\n",
    "        self._apply_initial_masks()\n",
    "\n",
    "        # Train\n",
    "        self.train()\n",
    "\n",
    "    def create_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "        self.model.add(Dense(4000, name=\"sparse_1\"))\n",
    "        self.model.add(SReLU(name=\"srelu1\"))\n",
    "        self.model.add(Dropout(0.3))\n",
    "\n",
    "        self.model.add(Dense(1000, name=\"sparse_2\"))\n",
    "        self.model.add(SReLU(name=\"srelu2\"))\n",
    "        self.model.add(Dropout(0.3))\n",
    "\n",
    "        self.model.add(Dense(4000, name=\"sparse_3\"))\n",
    "        self.model.add(SReLU(name=\"srelu3\"))\n",
    "        self.model.add(Dropout(0.3))\n",
    "\n",
    "        self.model.add(Dense(self.num_classes, name=\"dense_4\"))\n",
    "        self.model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # Build weights (needed before referencing layer outputs)\n",
    "        dummy = tf.zeros((1, 32, 32, 3), dtype=tf.float32)\n",
    "        _ = self.model(dummy, training=False)\n",
    "\n",
    "        # Activation probe model (after SReLU layers)\n",
    "        self.act_model = tf.keras.Model(\n",
    "            inputs=self.model.input,\n",
    "            outputs=[\n",
    "                self.model.get_layer(\"srelu1\").output,\n",
    "                self.model.get_layer(\"srelu2\").output,\n",
    "                self.model.get_layer(\"srelu3\").output,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Compile once\n",
    "        sgd = optimizers.SGD(learning_rate=self.learning_rate, momentum=self.momentum)\n",
    "        self.model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "    def _apply_initial_masks(self):\n",
    "        # Ensure sparse connectivity at initialization\n",
    "        l1 = self.model.get_layer(\"sparse_1\")\n",
    "        l2 = self.model.get_layer(\"sparse_2\")\n",
    "        l3 = self.model.get_layer(\"sparse_3\")\n",
    "\n",
    "        l1.kernel.assign(l1.kernel * tf.convert_to_tensor(self.wm1, dtype=l1.kernel.dtype))\n",
    "        l2.kernel.assign(l2.kernel * tf.convert_to_tensor(self.wm2, dtype=l2.kernel.dtype))\n",
    "        l3.kernel.assign(l3.kernel * tf.convert_to_tensor(self.wm3, dtype=l3.kernel.dtype))\n",
    "\n",
    "    def rewireMask(self, weights, noWeights, pre_scores=None, post_scores=None):\n",
    "        \"\"\"\n",
    "        Prune weights near 0 (legacy SET-style thresholds),\n",
    "        then add new edges. Growth is biased by neuron activity EMA after burn-in.\n",
    "        \"\"\"\n",
    "        # ---- Pruning (legacy logic) ----\n",
    "        values = np.sort(weights.ravel())\n",
    "        firstZeroPos = find_first_pos(values, 0)\n",
    "        lastZeroPos = find_last_pos(values, 0)\n",
    "\n",
    "        firstZeroPos = int(np.clip(firstZeroPos, 0, values.shape[0] - 1))\n",
    "        lastZeroPos = int(np.clip(lastZeroPos, 0, values.shape[0] - 1))\n",
    "\n",
    "        largestNegative = values[int((1 - self.zeta) * firstZeroPos)]\n",
    "        smallestPositive = values[int(\n",
    "            min(values.shape[0] - 1, lastZeroPos + self.zeta * (values.shape[0] - lastZeroPos))\n",
    "        )]\n",
    "\n",
    "        rewired = weights.copy()\n",
    "        rewired[rewired > smallestPositive] = 1\n",
    "        rewired[rewired < largestNegative] = 1\n",
    "        rewired[rewired != 1] = 0\n",
    "        core_mask = rewired.copy().astype(np.float32)\n",
    "\n",
    "        # ---- Growth (biased by neuron activity EMA) ----\n",
    "        nrAdd = 0\n",
    "        target_nonzeros = int(noWeights)\n",
    "        current_nonzeros = int(np.sum(rewired))\n",
    "        noRewires = int(target_nonzeros - current_nonzeros)\n",
    "\n",
    "        # If something goes odd, protect\n",
    "        if noRewires <= 0:\n",
    "            return rewired.astype(np.float32), core_mask\n",
    "\n",
    "        use_bias = (self.current_epoch >= self.burn_in_epochs) and (pre_scores is not None) and (post_scores is not None)\n",
    "        if use_bias:\n",
    "            p_pre = safe_probs(pre_scores)\n",
    "            p_post = safe_probs(post_scores)\n",
    "\n",
    "        rows, cols = rewired.shape\n",
    "\n",
    "        # Add edges until we hit the original parameter budget\n",
    "        while nrAdd < noRewires:\n",
    "            if use_bias:\n",
    "                i = np.random.choice(rows, p=p_pre)\n",
    "                j = np.random.choice(cols, p=p_post)\n",
    "            else:\n",
    "                i = np.random.randint(0, rows)\n",
    "                j = np.random.randint(0, cols)\n",
    "\n",
    "            if rewired[i, j] == 0:\n",
    "                rewired[i, j] = 1\n",
    "                nrAdd += 1\n",
    "\n",
    "        return rewired.astype(np.float32), core_mask\n",
    "\n",
    "    def weightsEvolution(self):\n",
    "        \"\"\"\n",
    "        Rewire each sparse layer:\n",
    "        - compute new masks using pruning + biased growth\n",
    "        - apply core mask to live weights (prunes + sets new edges to 0 initially)\n",
    "        \"\"\"\n",
    "        l1 = self.model.get_layer(\"sparse_1\")\n",
    "        l2 = self.model.get_layer(\"sparse_2\")\n",
    "        l3 = self.model.get_layer(\"sparse_3\")\n",
    "\n",
    "        w1 = l1.kernel.numpy()\n",
    "        w2 = l2.kernel.numpy()\n",
    "        w3 = l3.kernel.numpy()\n",
    "\n",
    "        # Layer1: pre=input neurons, post=hidden1 neurons\n",
    "        self.wm1, wm1Core = self.rewireMask(\n",
    "            w1, self.noPar1,\n",
    "            pre_scores=self.inp_ema,\n",
    "            post_scores=self.act1_ema\n",
    "        )\n",
    "\n",
    "        # Layer2: pre=hidden1, post=hidden2\n",
    "        self.wm2, wm2Core = self.rewireMask(\n",
    "            w2, self.noPar2,\n",
    "            pre_scores=self.act1_ema,\n",
    "            post_scores=self.act2_ema\n",
    "        )\n",
    "\n",
    "        # Layer3: pre=hidden2, post=hidden3\n",
    "        self.wm3, wm3Core = self.rewireMask(\n",
    "            w3, self.noPar3,\n",
    "            pre_scores=self.act2_ema,\n",
    "            post_scores=self.act3_ema\n",
    "        )\n",
    "\n",
    "        # Apply core masks to weights:\n",
    "        # - removes pruned edges immediately\n",
    "        # - new edges start at 0 (since core mask has 0 there)\n",
    "        l1.kernel.assign(l1.kernel * tf.convert_to_tensor(wm1Core, dtype=l1.kernel.dtype))\n",
    "        l2.kernel.assign(l2.kernel * tf.convert_to_tensor(wm2Core, dtype=l2.kernel.dtype))\n",
    "        l3.kernel.assign(l3.kernel * tf.convert_to_tensor(wm3Core, dtype=l3.kernel.dtype))\n",
    "\n",
    "    def read_data(self):\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        y_train = to_categorical(y_train, self.num_classes)\n",
    "        y_test = to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        x_train = x_train.astype(\"float32\")\n",
    "        x_test = x_test.astype(\"float32\")\n",
    "\n",
    "        # normalize (same as legacy)\n",
    "        mean = np.mean(x_train, axis=0)\n",
    "        std = np.std(x_train, axis=0) + 1e-8\n",
    "        x_train = (x_train - mean) / std\n",
    "        x_test = (x_test - mean) / std\n",
    "\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    def train(self):\n",
    "        x_train, x_test, y_train, y_test = self.read_data()\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,\n",
    "            samplewise_center=False,\n",
    "            featurewise_std_normalization=False,\n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False\n",
    "        )\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        self.model.summary()\n",
    "\n",
    "        steps_per_epoch = x_train.shape[0] // self.batch_size\n",
    "\n",
    "        base_it = datagen.flow(x_train, y_train, batch_size=self.batch_size)\n",
    "        tracked = TrackingFlow(base_it, self)\n",
    "\n",
    "        set_cb = SETCallback(self)\n",
    "\n",
    "        self.model.fit(\n",
    "            iter(tracked),\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=self.maxepoches,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[set_cb],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        self.accuracies_per_epoch = np.asarray(self.accuracies_per_epoch, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d78b23-4c0c-49d2-9202-162a03ff32ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Sparse Matrix: No parameters, NoRows, NoCols  141345 3072 4000\n",
      "Create Sparse Matrix: No parameters, NoRows, NoCols  99914 4000 1000\n",
      "Create Sparse Matrix: No parameters, NoRows, NoCols  99612 1000 4000\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " sparse_1 (Dense)            (None, 4000)              12292000  \n",
      "                                                                 \n",
      " srelu1 (SReLU)              (None, 4000)              4         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4000)              0         \n",
      "                                                                 \n",
      " sparse_2 (Dense)            (None, 1000)              4001000   \n",
      "                                                                 \n",
      " srelu2 (SReLU)              (None, 1000)              4         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " sparse_3 (Dense)            (None, 4000)              4004000   \n",
      "                                                                 \n",
      " srelu3 (SReLU)              (None, 4000)              4         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4000)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                40010     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20337022 (77.58 MB)\n",
      "Trainable params: 20337022 (77.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "  6/500 [..............................] - ETA: 1:06 - loss: 2.3020 - accuracy: 0.1233WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0284s vs `on_train_batch_end` time: 0.1099s). Check your callbacks.\n",
      "100/500 [=====>........................] - ETA: 1:08 - loss: 2.3006 - accuracy: 0.1186"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSET_MLP_CIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     np\u001b[38;5;241m.\u001b[39msavetxt(\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/set_mlp_neuronEMA_growth_cifar10_acc.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         np\u001b[38;5;241m.\u001b[39masarray(model\u001b[38;5;241m.\u001b[39maccuracies_per_epoch)\n\u001b[1;32m      9\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36mSET_MLP_CIFAR10.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_initial_masks()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 230\u001b[0m, in \u001b[0;36mSET_MLP_CIFAR10.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m tracked \u001b[38;5;241m=\u001b[39m TrackingFlow(base_it, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    228\u001b[0m set_cb \u001b[38;5;241m=\u001b[39m SETCallback(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtracked\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxepoches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mset_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracies_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracies_per_epoch, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:1789\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1788\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1789\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mSETCallback.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     23\u001b[0m l2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m l3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_mask_to_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwm1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_mask_to_layer(l2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mwm2)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_mask_to_layer(l3, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mwm3)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mSETCallback._apply_mask_to_layer\u001b[0;34m(layer, mask_np)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply_mask_to_layer\u001b[39m(layer: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense, mask_np: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m---> 14\u001b[0m     mask_tf \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     layer\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39massign(layer\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m*\u001b[39m mask_tf)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py:328\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    327\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 328\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py:90\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[1;32m     88\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[1;32m     89\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[1;32m     92\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    model = SET_MLP_CIFAR10()\n",
    "\n",
    "    np.savetxt(\n",
    "        \"results/set_mlp_neuronEMA_growth_cifar10_acc.txt\",\n",
    "        np.asarray(model.accuracies_per_epoch)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095efbc5-b8a9-4b2a-a7a4-6eeba17c5a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
